{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Hyper-Optimized Proxy System.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7fb6ac65",
      "metadata": {},
      "source": "# Hyper-Optimized Proxy System\n\nThis notebook implements a proxy system that sits between client applications and an open router endpoint. It includes the following advanced features:\n\n- **Proxy Routing:** Forwards client requests to a simulated open router endpoint.\n- **Low-Latency Streaming:** Streams responses in real time using asynchronous I/O.\n- **DSPY Optimization Module:** Monitors operational metrics and (via a simulated neuro-symbolic engine) automatically toggles an optimized routing path.\n- **Gating Mechanism:** Uses both heuristic rules (modeled with abstract algebra concepts) and an enhanced GSPO reinforcement learning agent to decide whether subsequent requests should use the optimized (streaming) execution path.\n- **Robust Error Handling & Simulated Security:** Implements basic error handling and simulates authentication via an API key check.\n- **Evaluation Framework:** Collects metrics (latency, time-to-first-byte, throughput) and plots performance comparisons.\n\n*Note: Some elements (e.g. self-modifying code, abstract algebra modeling) are simulated for demonstration purposes.*"
    },
    {
      "cell_type": "code",
      "id": "11c7b2df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T12:00:00Z",
          "iopub.execute_output": "2025-02-09T12:00:00Z"
        }
      },
      "source": "import asyncio\nimport time\nimport random\nimport statistics\nimport matplotlib.pyplot as plt\n\n# Simulated logging function\ndef log(message):\n    print(f\"[LOG {time.strftime('%H:%M:%S')}] {message}\")\n\n# Security decorator (simulated API key check)\ndef require_api_key(func):\n    async def wrapper(*args, **kwargs):\n        # In a real system, check headers or tokens; here we simulate with a fixed key\n        api_key = kwargs.get('api_key', None)\n        if api_key != 'secret-key':\n            raise PermissionError('Invalid API key')\n        return await func(*args, **kwargs)\n    return wrapper\n\n# Utility: Simulated abstract algebra operation for state updates\n# Here we define a simple semigroup operation for merging optimization updates\n\ndef semigroup_merge(state1, state2):\n    # For simplicity, state is represented as a dict with a numeric value\n    # The semigroup operation is addition\n    merged = {'value': state1.get('value', 0) + state2.get('value', 0)}\n    return merged\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ea054f9d",
      "metadata": {},
      "source": "## Simulated Router Endpoint\n\nThis function simulates an open router endpoint. It yields several chunks of data with a short delay between each chunk. In a production system, this would be an external service."
    },
    {
      "cell_type": "code",
      "id": "d6e341b0",
      "metadata": {},
      "source": "async def router_endpoint(request_id: int):\n    \"\"\"\n    Simulate an open router endpoint that returns data in chunks.\n    Each chunk is produced after a short delay to emulate network latency and processing time.\n    \"\"\"\n    num_chunks = 5\n    for i in range(1, num_chunks + 1):\n        await asyncio.sleep(0.1)  # simulate delay\n        # Occasionally simulate an error\n        if random.random() < 0.05:\n            raise Exception(f\"Router endpoint error on chunk {i} for request {request_id}\")\n        yield f\"chunk_{i}_for_request_{request_id}\"\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "efc1d6c6",
      "metadata": {},
      "source": "## Proxy Server with Robust Error Handling & Security\n\nThe `ProxyServer` class forwards client requests to the router endpoint. It supports both a baseline (buffered) mode and an optimized (streaming) mode. A simple security check is performed via the `require_api_key` decorator."
    },
    {
      "cell_type": "code",
      "id": "4b5e2222",
      "metadata": {},
      "source": "class ProxyServer:\n    def __init__(self):\n        # Flag: False = baseline, True = optimized streaming\n        self.use_optimized_path = False\n        # Optional RL agent\n        self.gspo_agent = None\n        # Internal optimization state (for neuro-symbolic simulation)\n        self.optimization_state = {'value': 0}\n\n    def enable_gspo(self, agent):\n        self.gspo_agent = agent\n\n    def set_optimized(self, flag: bool):\n        log(f\"Setting optimized path to {flag}\")\n        self.use_optimized_path = flag\n\n    @require_api_key\n    async def process_request(self, request_id: int, api_key=None):\n        \"\"\"\n        Process a client request:\n        - If optimized (streaming) mode is active, yield each chunk immediately.\n        - Otherwise, buffer all chunks and yield a combined response.\n        Robust error handling is built in.\n        \"\"\"\n        try:\n            # Determine which mode to use\n            use_streaming = self.use_optimized_path\n            if self.gspo_agent:\n                action = self.gspo_agent.choose_action()\n                use_streaming = (action == 1)\n            router_gen = router_endpoint(request_id)\n            if use_streaming:\n                async for chunk in router_gen:\n                    yield chunk\n            else:\n                chunks = []\n                async for chunk in router_gen:\n                    chunks.append(chunk)\n                yield \" \".join(chunks)\n        except Exception as e:\n            log(f\"Error processing request {request_id}: {e}\")\n            yield f\"Error: {e}\"\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7d1a79ee",
      "metadata": {},
      "source": "## DSPY Optimization Module with Neuro-Symbolic Reasoning\n\nThis module monitors request performance metrics and uses a heuristic combined with a simulated symbolic rule engine (using a semigroup merge operation) to update the optimization state. When conditions are met (e.g., average latency exceeds a threshold), it toggles the proxy to optimized streaming mode."
    },
    {
      "cell_type": "code",
      "id": "4e3d7c3d",
      "metadata": {},
      "source": "class DspyOptimizer:\n    def __init__(self, proxy: ProxyServer, latency_threshold: float = 0.25, sample_size: int = 5):\n        self.proxy = proxy\n        self.latency_threshold = latency_threshold\n        self.sample_size = sample_size\n        self.metrics_log = []\n        # Simulated symbolic state update\n        self.symbolic_state = {'value': 0}\n\n    def record_request_result(self, latency: float, ttfb: float):\n        self.metrics_log.append(latency)\n        if len(self.metrics_log) > self.sample_size:\n            self.metrics_log.pop(0)\n\n    def symbolic_rule_update(self):\n        \"\"\"\n        Simulate a symbolic rule: if average latency > threshold, create an update state\n        and merge it with the current optimization state using a semigroup operation.\n        \"\"\"\n        if len(self.metrics_log) == self.sample_size:\n            avg_latency = sum(self.metrics_log) / self.sample_size\n            if avg_latency > self.latency_threshold:\n                # Create an update state proportional to the average latency\n                update_state = {'value': avg_latency}\n                # Merge with the current symbolic state\n                self.symbolic_state = semigroup_merge(self.symbolic_state, update_state)\n                log(f\"Symbolic state updated to: {self.symbolic_state}\")\n                # If symbolic state exceeds a set value, toggle optimized path\n                if self.symbolic_state['value'] > (self.latency_threshold * self.sample_size):\n                    self.proxy.set_optimized(True)\n\n    def analyze_and_optimize(self):\n        if len(self.metrics_log) == self.sample_size:\n            avg_latency = sum(self.metrics_log) / self.sample_size\n            log(f\"Average latency over last {self.sample_size} requests: {avg_latency:.3f} sec\")\n            self.symbolic_rule_update()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "13e7dfbf",
      "metadata": {},
      "source": "## Enhanced GSPO Reinforcement Learning Agent\n\nThis agent uses an epsilon-greedy strategy with incremental Q-value updates. It represents a two-action bandit (0: baseline, 1: optimized) but now includes a simple state variable update and more detailed logging."
    },
    {
      "cell_type": "code",
      "id": "0a1e9b2b",
      "metadata": {},
      "source": "class GspoAgent:\n    def __init__(self, epsilon: float = 0.1):\n        self.epsilon = epsilon\n        self.values = [0.0, 0.0]  # estimated Q-values for actions 0 and 1\n        self.counts = [0, 0]\n        self.last_action = None\n\n    def choose_action(self):\n        if random.random() < self.epsilon:\n            action = random.choice([0, 1])\n            log(f\"[RL] Exploring: selected action {action}\")\n        else:\n            action = 0 if self.values[0] >= self.values[1] else 1\n            log(f\"[RL] Exploiting: selected action {action}\")\n        self.last_action = action\n        return action\n\n    def update(self, reward: float):\n        action = self.last_action\n        if action is None:\n            return\n        self.counts[action] += 1\n        n = self.counts[action]\n        old_value = self.values[action]\n        self.values[action] += (reward - old_value) / n\n        log(f\"[RL] Updated Q-value for action {action}: {self.values[action]:.3f}\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ed2d5be7",
      "metadata": {},
      "source": "## Evaluation Framework and Metrics\n\nThe evaluation framework simulates multiple concurrent requests, records latency and time-to-first-byte (TTFB), and plots the performance metrics. It distinguishes between baseline (non-streaming) and optimized (streaming) modes."
    },
    {
      "cell_type": "code",
      "id": "8c1d6d2f",
      "metadata": {},
      "source": "async def run_requests(proxy, num_requests: int, api_key='secret-key'):\n    results = []  # (latency, ttfb, used_optimized)\n    tasks = []\n    \n    async def handle_request(rid):\n        try:\n            start_time = time.perf_counter()\n            first_byte_time = None\n            used_optimized = proxy.use_optimized_path\n            # If RL agent is active, choose action already in process_request\n            response_chunks = []\n            async for chunk in proxy.process_request(rid, api_key=api_key):\n                if first_byte_time is None:\n                    first_byte_time = time.perf_counter()\n                response_chunks.append(chunk)\n            end_time = time.perf_counter()\n            latency = end_time - start_time\n            ttfb = first_byte_time - start_time if first_byte_time else latency\n            results.append((latency, ttfb, used_optimized))\n            # Update RL agent if available\n            if proxy.gspo_agent:\n                proxy.gspo_agent.update(reward=-latency)  \n            optimizer.record_request_result(latency, ttfb)\n            optimizer.analyze_and_optimize()\n        except Exception as e:\n            log(f\"Request {rid} encountered an error: {e}\")\n            results.append((None, None, proxy.use_optimized_path))\n\n    for rid in range(1, num_requests + 1):\n        tasks.append(asyncio.create_task(handle_request(rid)))\n    await asyncio.gather(*tasks)\n    return results\n\n# Function to summarize and plot metrics\ndef summarize_and_plot(results, phase_label):\n    latencies = [r[0] for r in results if r[0] is not None]\n    ttfbs = [r[1] for r in results if r[1] is not None]\n    avg_latency = statistics.mean(latencies) if latencies else 0\n    avg_ttfb = statistics.mean(ttfbs) if ttfbs else 0\n    throughput = len(latencies) / sum(latencies) if sum(latencies) > 0 else 0\n    log(f\"[{phase_label}] Avg latency: {avg_latency:.3f} sec, Avg TTFB: {avg_ttfb:.3f} sec, Throughput: {throughput:.2f} req/sec\")\n    \n    plt.figure(figsize=(8,4))\n    plt.hist(latencies, bins=10, alpha=0.7, label='Latency')\n    plt.xlabel('Latency (sec)')\n    plt.ylabel('Frequency')\n    plt.title(f'{phase_label} Latency Distribution')\n    plt.legend()\n    plt.show()\n    return avg_latency, avg_ttfb, throughput\n\n# Initialize proxy, optimizer, and RL agent\nproxy = ProxyServer()\noptimizer = DspyOptimizer(proxy, latency_threshold=0.25, sample_size=5)\n\nuse_rl = True\nif use_rl:\n    agent = GspoAgent(epsilon=0.1)\n    proxy.enable_gspo(agent)\n\n# Run simulation in two phases\nnum_total_requests = 20\nlog(\"--- Running simulation ---\")\n\nresults = asyncio.run(run_requests(proxy, num_total_requests))\n\n# Separate results: first half baseline, second half (after potential optimization)\nbaseline_results = results[:10]\noptimized_results = results[10:]\n\nlog(\"--- Baseline Phase ---\")\nbase_avg_lat, base_avg_ttfb, base_throughput = summarize_and_plot(baseline_results, 'Baseline')\n\nlog(\"--- Optimized Phase ---\")\nopt_avg_lat, opt_avg_ttfb, opt_throughput = summarize_and_plot(optimized_results, 'Optimized')\n\n# Count how many requests used the optimized path in the second phase\noptimized_used_count = sum(1 for r in optimized_results if r[2])\nlog(f\"Optimized Phase: {optimized_used_count} out of {len(optimized_results)} requests used the optimized path\")\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4b48e8b0",
      "metadata": {},
      "source": "## Conclusion\n\nThis notebook demonstrates a hyper-optimized proxy system that forwards requests to a simulated router endpoint while streaming responses concurrently. The system integrates:\n\n- A **DSPY Optimization Module** with a simulated neuro-symbolic rule engine (using semigroup operations) that updates optimization state based on latency metrics.\n- An enhanced **GSPO Reinforcement Learning Agent** that learns, via an epsilon‑greedy strategy, to select between baseline and optimized (streaming) paths.\n- Robust error handling and simulated security checks (via an API key requirement).\n- An evaluation framework that gathers performance metrics and plots latency distributions for both baseline and optimized phases.\n\nWhile this is a simulation, the design illustrates how advanced techniques such as neuro‑symbolic reasoning, self‑optimization, and reinforcement learning can be integrated into a proxy system to reduce latency and improve throughput in real time."
    }
  ]
}
