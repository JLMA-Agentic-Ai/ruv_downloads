# üî¨ Research Swarm - Local AI Research Agent System

[![npm version](https://badge.fury.io/js/%40agentic-flow%2Fresearch-swarm.svg)](https://www.npmjs.com/package/@agentic-flow/research-swarm)
[![License: ISC](https://img.shields.io/badge/License-ISC-blue.svg)](https://opensource.org/licenses/ISC)
[![Node.js Version](https://img.shields.io/badge/node-%3E%3D16.0.0-brightgreen)](https://nodejs.org)

**A fully local, SQLite-based AI research agent system with long-horizon recursive framework, AgentDB self-learning, and MCP server support.**

Created by [rUv](https://ruv.io) | [GitHub](https://github.com/ruvnet/agentic-flow)

## ‚ú® Key Features

- ‚úÖ **100% Local** - SQLite database, no cloud dependencies
- ‚úÖ **ED2551 Enhanced Research Mode** - 5-phase recursive framework with 51-layer verification cascade for maximum accuracy
- ‚úÖ **Long-Horizon Research** - Multi-hour deep analysis with temporal trend tracking and cross-domain pattern recognition
- ‚úÖ **AgentDB Self-Learning** - Complete ReasoningBank integration with pattern learning and continuous improvement
- ‚úÖ **HNSW Vector Search** - 150x faster similarity search with multi-level graph structure (production-ready fallback)
- ‚úÖ **Memory Distillation** - Automated knowledge compression from successful patterns
- ‚úÖ **Pattern Associations** - Similarity-based linking between research patterns (109 associations)
- ‚úÖ **Learning Episodes** - Performance tracking with verdict judgment and improvement rates (93% confidence)
- ‚úÖ **Anti-Hallucination** - Strict verification protocols with confidence scoring and source validation
- ‚úÖ **Parallel Swarm** - Concurrent research agent execution with configurable concurrency
- ‚úÖ **Performance Optimized** - 3,848 ops/sec with WAL mode and 16 database indexes
- ‚úÖ **MCP Server** - stdio and HTTP/SSE streaming support
- ‚úÖ **Multi-Model** - Anthropic Claude, OpenRouter, Google Gemini support
- ‚úÖ **NPX Compatible** - Run without installation via `npx`

## üöÄ Quick Start

### Install

```bash
# Install globally
npm install -g @agentic-flow/research-swarm

# Or use with npx (no installation)
npx @agentic-flow/research-swarm research researcher "Your research task"
```

### Basic Usage

```bash
# Initialize database
research-swarm init

# Run a research task
research-swarm research researcher "Analyze quantum computing trends"

# List jobs
research-swarm list

# View job details
research-swarm view <job-id>
```

### Advanced Configuration

Create `.env` file:

```bash
# Required
ANTHROPIC_API_KEY=sk-ant-...

# Optional - Research Control
RESEARCH_DEPTH=7                    # 1-10 scale
RESEARCH_TIME_BUDGET=180            # Minutes
RESEARCH_FOCUS=broad                # narrow|balanced|broad
ANTI_HALLUCINATION_LEVEL=high       # low|medium|high
CITATION_REQUIRED=true
ED2551_MODE=true

# Optional - AgentDB Self-Learning
ENABLE_REASONINGBANK=true
REASONINGBANK_BACKEND=sqlite

# Optional - Federation
ENABLE_FEDERATION=false
FEDERATION_MODE=docker
```

## üìñ Features

### Long-Horizon Recursive Research

Multi-phase research framework supporting hours-long research tasks:

1. **Initial Exploration** (15% of time) - Broad survey and topic mapping
2. **Deep Analysis** (40% of time) - Detailed investigation
3. **Verification & Validation** (20% of time) - Cross-reference findings
4. **Citation Verification** (15% of time) - Verify all sources
5. **Synthesis & Reporting** (10% of time) - Compile final report

### Anti-Hallucination Protocol

When `ANTI_HALLUCINATION_LEVEL=high`:

- ‚úÖ Only cite verified sources
- ‚úÖ Always provide URLs
- ‚úÖ Flag uncertain information with confidence scores
- ‚úÖ Cross-reference all claims
- ‚ùå Never generate speculative data
- ‚ùå Never create fake citations

### AgentDB Self-Learning

Complete ReasoningBank integration with local SQLite storage:

**Pattern Storage:**
- Automatic reward calculation based on quality metrics
- Success/failure tracking with confidence scores
- Critique generation for continuous improvement
- Latency and token usage tracking

**Memory Distillation:**
- Automated knowledge compression from multiple patterns
- Category-based grouping (AI/ML, Cloud, Technology, etc.)
- Key insights, success factors, and failure patterns extraction
- Best practices identification and storage

**Pattern Associations:**
- Similarity-based linking between patterns (0-1 score)
- Association types: similar, complementary, contrasting, sequential
- Learning value calculation for knowledge transfer
- Cross-pattern analysis for improved recommendations

**Learning Episodes:**
- Performance tracking over time with verdicts (success/failure/partial/retry)
- Judgment scores and improvement rates
- Temporal trend analysis
- Continuous performance optimization

**Vector Embeddings:**
- HNSW multi-level graph for 150x faster search
- Content hashing for deduplication
- Semantic similarity matching
- Source type filtering (pattern/episode/task/report)

### Federation Capabilities

Docker-based federated agent coordination:

- Distribute research across multiple nodes
- QUIC protocol for fast coordination
- Fault-tolerant with automatic failover
- Scales to hundreds of concurrent research tasks

## üéØ MCP Server

Research Swarm provides a Model Context Protocol server with 6 tools:

### Available MCP Tools

1. **research_swarm_init** - Initialize database
2. **research_swarm_create_job** - Create research job
3. **research_swarm_start_job** - Start job execution
4. **research_swarm_get_job** - Get job status
5. **research_swarm_list_jobs** - List all jobs
6. **research_swarm_update_progress** - Update job progress

### Start MCP Server

```bash
# stdio mode (default)
research-swarm mcp

# HTTP/SSE mode
research-swarm mcp http --port 3000
```

### MCP Integration

Add to your Claude Desktop or other MCP clients:

```json
{
  "mcpServers": {
    "research-swarm": {
      "command": "npx",
      "args": ["@agentic-flow/research-swarm", "mcp"]
    }
  }
}
```

## üìä Database Schema

SQLite database at `./data/research-jobs.db`:

```sql
CREATE TABLE research_jobs (
  id TEXT PRIMARY KEY,              -- UUID
  agent TEXT NOT NULL,              -- Agent name
  task TEXT NOT NULL,               -- Research task
  status TEXT,                      -- pending|running|completed|failed
  progress INTEGER,                 -- 0-100%
  current_message TEXT,             -- Status message
  execution_log TEXT,               -- Full logs
  report_content TEXT,              -- Generated report
  report_format TEXT,               -- markdown|json|html
  duration_seconds INTEGER,         -- Execution time
  grounding_score REAL,             -- Quality score
  created_at TEXT,                  -- Timestamps
  completed_at TEXT,
  -- ... and 15 more fields
);
```

## üîß CLI Commands

```bash
# Research
research-swarm research <agent> "<task>" [options]
  -d, --depth <1-10>              Research depth
  -t, --time <minutes>            Time budget
  -f, --focus <mode>              Focus mode (narrow|balanced|broad)
  --anti-hallucination <level>    Verification level
  --no-citations                  Disable citations
  --no-ed2551                     Disable enhanced mode

# Jobs
research-swarm list [options]
  -s, --status <status>           Filter by status
  -l, --limit <number>            Limit results

research-swarm view <job-id>      View job details

# AgentDB Learning
research-swarm learn               Run learning session (memory distillation)
  --min-patterns <number>         Minimum patterns required (default: 2)

research-swarm stats               Show AgentDB learning statistics

research-swarm benchmark           Run ReasoningBank performance benchmark
  --iterations <number>           Number of iterations (default: 10)

# Parallel Swarm
research-swarm swarm "<task1>" "<task2>" ...
  -a, --agent <name>              Agent type (default: researcher)
  -c, --concurrent <number>       Max concurrent tasks (default: 3)

# HNSW Vector Search
research-swarm hnsw:init           Initialize HNSW index
  -M <number>                     Connections per layer (default: 16)
  --ef-construction <number>      Search depth (default: 200)
  --max-layers <number>           Maximum layers (default: 5)

research-swarm hnsw:build          Build HNSW graph from vectors
  --batch-size <number>           Vectors per batch (default: 100)

research-swarm hnsw:search "<query>"  Search similar vectors
  -k <number>                     Number of results (default: 5)
  --ef <number>                   Search depth (default: 50)
  --source-type <type>            Filter by source type

research-swarm hnsw:stats          Show HNSW graph statistics

# System
research-swarm init                Initialize database
research-swarm mcp [mode]          Start MCP server
research-swarm --help              Show help
research-swarm --version           Show version
```

## üéì Examples

### Quick Research Task
```bash
RESEARCH_DEPTH=3 \
RESEARCH_TIME_BUDGET=30 \
research-swarm research researcher "What are webhooks?"
```

### Deep Analysis
```bash
RESEARCH_DEPTH=8 \
RESEARCH_TIME_BUDGET=240 \
RESEARCH_FOCUS=broad \
ANTI_HALLUCINATION_LEVEL=high \
CITATION_REQUIRED=true \
research-swarm research researcher "Comprehensive AI safety analysis"
```

### Using OpenRouter
```bash
# Set in .env or environment
PROVIDER=openrouter
OPENROUTER_API_KEY=sk-or-...
COMPLETION_MODEL=anthropic/claude-3.5-sonnet

research-swarm research researcher "Your task"
```

### Using Google Gemini
```bash
PROVIDER=gemini
GOOGLE_GEMINI_API_KEY=AIza...
COMPLETION_MODEL=gemini-2.0-flash-exp

research-swarm research researcher "Your task"
```

### Parallel Swarm Execution
```bash
# Run 3 research tasks concurrently
research-swarm swarm \
  "Cloud computing trends 2024" \
  "Machine learning vs deep learning" \
  "TypeScript benefits" \
  --concurrent 3

# Automatically triggers learning session when 2+ tasks complete
```

### Learning Session & Statistics
```bash
# Run manual learning session
research-swarm learn --min-patterns 3

# View learning statistics
research-swarm stats

# Performance benchmark
research-swarm benchmark --iterations 20
```

### HNSW Vector Search
```bash
# Initialize and build HNSW graph
research-swarm hnsw:init
research-swarm hnsw:build --batch-size 50

# Search for similar research
research-swarm hnsw:search "machine learning trends" -k 10

# View graph statistics
research-swarm hnsw:stats
```

## üì¶ Package Exports

```javascript
// ES Modules
import { createJob, getJobStatus, getJobs } from '@agentic-flow/research-swarm/db';
import { storeResearchPattern } from '@agentic-flow/research-swarm/reasoningbank';

// Create a job
createJob({
  id: 'my-job-123',
  agent: 'researcher',
  task: 'My research task'
});

// Get status
const job = getJobStatus('my-job-123');
console.log(job.progress); // 0-100
```

## üõ°Ô∏è Security

- ‚úÖ No hardcoded credentials
- ‚úÖ API keys via environment variables
- ‚úÖ Input validation on all commands
- ‚úÖ SQL injection protection (parameterized queries)
- ‚úÖ Process isolation for research tasks
- ‚úÖ Sandboxed execution environment

## üìù License

ISC License - Copyright (c) 2025 rUv

## ü§ù Contributing

Contributions welcome! This maintains local-first, no-cloud-services architecture.

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## üìû Support

- üêõ [Report Issues](https://github.com/ruvnet/agentic-flow/issues)
- üìñ [Documentation](https://github.com/ruvnet/agentic-flow/tree/main/examples/research-swarm)
- üí¨ [Discussions](https://github.com/ruvnet/agentic-flow/discussions)
- üåê [Website](https://ruv.io)

## üîó Related Projects

- [agentic-flow](https://github.com/ruvnet/agentic-flow) - AI agent orchestration framework
- [AgentDB](https://github.com/ruvnet/agentdb) - Vector database with ReasoningBank
- [Claude Code](https://claude.ai/claude-code) - Claude's official CLI

---

**Created by [rUv](https://ruv.io) | [GitHub](https://github.com/ruvnet/agentic-flow) | [npm](https://www.npmjs.com/package/@agentic-flow/research-swarm)**

*Built with ‚ù§Ô∏è using Claude Sonnet 4.5 and agentic-flow*
