{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install -q mergekit transformers accelerate sdv\n",
    "\n",
    "# Import libraries\n",
    "import mergekit\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sdv.tabular import CTGAN\n",
    "\n",
    "# Load pre-trained Mistral models using mergekit\n",
    "mistral_chat = mergekit.load_model('mistral-7b-chat')\n",
    "mistral_code = mergekit.load_model('mistral-7b-code') \n",
    "\n",
    "# Define merge configuration\n",
    "merge_config = {\n",
    "    'merge_method': 'slerp',\n",
    "    'models': [mistral_chat, mistral_code],\n",
    "    'parameters': {\n",
    "        't': 0.5\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform model merging\n",
    "merged_model = mergekit.merge(merge_config)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/xglm-7.5B\")\n",
    "\n",
    "# Employee class template\n",
    "class Employee:\n",
    "    def __init__(self, name, email, role):\n",
    "        self.name = name\n",
    "        self.email = email\n",
    "        self.role = role\n",
    "\n",
    "    def send_email(self, recipient, subject, body):\n",
    "        prompt = f\"\"\"Write an email from {self.name} to {recipient}\n",
    "Subject: {subject}\n",
    "{body}\"\"\"\n",
    "        \n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "        output = merged_model.generate(input_ids, max_length=200)\n",
    "        email_text = tokenizer.decode(output[0])\n",
    "\n",
    "        return email_text\n",
    "\n",
    "    def write_code(self, language, instructions):\n",
    "        prompt = f\"\"\"Write {language} code to {instructions}\"\"\"\n",
    "        \n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids  \n",
    "        output = merged_model.generate(input_ids, max_length=400)\n",
    "        code = tokenizer.decode(output[0])\n",
    "\n",
    "        return code\n",
    "\n",
    "    def fill_timesheet(self, date, hours, project):\n",
    "        prompt = f\"\"\"Fill out this timesheet entry:\n",
    "Date: {date}\n",
    "Hours Worked: {hours} \n",
    "Project: {project}\n",
    "\"\"\"\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "        output = merged_model.generate(input_ids, max_length=100)  \n",
    "        timesheet_entry = tokenizer.decode(output[0])\n",
    "\n",
    "        return timesheet_entry\n",
    "\n",
    "    def plan_task(self, task_description):\n",
    "        prompt = f\"\"\"Create a plan to complete this task: {task_description}\n",
    "Include specific action items.\"\"\"\n",
    "\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "        output = merged_model.generate(input_ids, max_length=300)\n",
    "        task_plan = tokenizer.decode(output[0])  \n",
    "\n",
    "        return task_plan\n",
    "\n",
    "# Generate synthetic employee data using SDV\n",
    "employee_data = [\n",
    "    {'name': 'John Doe', 'email': 'john@company.com', 'role': 'Software Engineer'},\n",
    "    {'name': 'Jane Smith', 'email': 'jane@company.com', 'role': 'Data Scientist'}, \n",
    "    {'name': 'Bob Johnson', 'email': 'bob@company.com', 'role': 'Product Manager'}\n",
    "]\n",
    "\n",
    "ctgan = CTGAN()\n",
    "ctgan.fit(employee_data)\n",
    "\n",
    "synthetic_employees = ctgan.sample(50)\n",
    "\n",
    "print(synthetic_employees.head())\n",
    "\n",
    "# Fine-tune merged model on synthetic employee data\n",
    "def finetune(model, tokenizer, data, epochs=3):\n",
    "    model.train()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for row in data.itertuples(index=False):\n",
    "            prompt = f\"\"\"{row.name} is a {row.role} at our company.\n",
    "Their email is {row.email}.\"\"\"\n",
    "\n",
    "            input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "            loss = model(input_ids, labels=input_ids)[0]\n",
    "            \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "    return model\n",
    "\n",
    "tuned_model = finetune(merged_model, tokenizer, synthetic_employees)\n",
    "\n",
    "# Example usage with fine-tuned model\n",
    "employee1 = Employee(\"Sarah Connor\", \"sarah@company.com\", \"ML Engineer\")\n",
    "\n",
    "# Send email\n",
    "email = employee1.send_email(\"john@company.com\", \"Model Update\", \"Hi John, I've finished fine-tuning the new model on the synthetic data...\")\n",
    "print(email)\n",
    "\n",
    "# Write code \n",
    "code = employee1.write_code(\"Python\", \"load a CSV file into a Pandas dataframe\")  \n",
    "print(code)\n",
    "\n",
    "# Fill timesheet \n",
    "timesheet = employee1.fill_timesheet(\"2024-03-16\", 6, \"Synthetic Data Generation\")\n",
    "print(timesheet)  \n",
    "\n",
    "# Plan task\n",
    "task_plan = employee1.plan_task(\"Evaluate model performance on test set\")\n",
    "print(task_plan)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}