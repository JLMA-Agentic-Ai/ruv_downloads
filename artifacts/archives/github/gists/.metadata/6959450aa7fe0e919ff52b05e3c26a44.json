{
  "url": "https://api.github.com/gists/6959450aa7fe0e919ff52b05e3c26a44",
  "forks_url": "https://api.github.com/gists/6959450aa7fe0e919ff52b05e3c26a44/forks",
  "commits_url": "https://api.github.com/gists/6959450aa7fe0e919ff52b05e3c26a44/commits",
  "id": "6959450aa7fe0e919ff52b05e3c26a44",
  "node_id": "G_kwDOACzGetoAIDY5NTk0NTBhYTdmZTBlOTE5ZmY1MmIwNWUzYzI2YTQ0",
  "git_pull_url": "https://gist.github.com/6959450aa7fe0e919ff52b05e3c26a44.git",
  "git_push_url": "https://gist.github.com/6959450aa7fe0e919ff52b05e3c26a44.git",
  "html_url": "https://gist.github.com/ruvnet/6959450aa7fe0e919ff52b05e3c26a44",
  "files": {
    "Contextual Retrieval system.md": {
      "filename": "Contextual Retrieval system.md",
      "type": "text/markdown",
      "language": "Markdown",
      "raw_url": "https://gist.githubusercontent.com/ruvnet/6959450aa7fe0e919ff52b05e3c26a44/raw/f8dac7ea83f34f0af621c81dbd7347eb13b84a10/Contextual%20Retrieval%20system.md",
      "size": 17191,
      "truncated": false,
      "content": "# Contextual Retrieval System with Supabase Storage\n\n## Overview\n\nThis Contextual Retrieval System enhances the accuracy and relevance of information retrieval by incorporating context into the search process. It leverages OpenAI's GPT-4 model, LlamaIndex, FastAPI, LiteLLM, and uses Supabase for both vector storage and document storage and management.\n\n## Key Components\n\n1. **LiteLLM**: For flexible integration with OpenAI's GPT-4 model.\n2. **Supabase Postgres with pgvector**: For vector storage, enabling efficient similarity searches.\n3. **Supabase Storage**: For centralized document storage and management.\n4. **FastAPI**: For building an asynchronous web API.\n5. **LlamaIndex**: For document processing and indexing.\n6. **DiskCache**: For caching to reduce redundant computations and API calls.\n7. **Loguru**: For enhanced logging capabilities.\n\n## Benefits\n\n- **Improved Accuracy**: Reduces retrieval failures by preserving crucial context.\n- **Enhanced Relevance**: Provides more relevant search results by considering broader context.\n- **Versatility**: Applicable across various domains.\n- **Efficiency in Large Datasets**: Effective when dealing with large, complex datasets.\n- **Better User Experience**: Offers context-aware and accurate responses.\n\n---\n\n## Folder and File Structure\n\n```\ncontextual_retrieval/\n├── app/\n│   ├── __init__.py\n│   ├── main.py\n│   ├── utils.py\n│   ├── config.py\n│   ├── supabase_client.py\n├── cache/\n│   └── (Cache files stored here)\n├── supabase/\n│   └── migrations/\n│       └── 20231018000000_create_embeddings_table.sql\n├── .env\n├── Dockerfile\n├── docker-compose.yml\n├── install.sh\n├── pyproject.toml\n└── README.md\n```\n\n- `app/`: Contains the application code.\n  - `__init__.py`: Initializes the package.\n  - `main.py`: The main FastAPI application.\n  - `utils.py`: Utility functions.\n  - `config.py`: Configuration settings.\n  - `supabase_client.py`: Supabase client initialization.\n- `cache/`: Cache directory for `diskcache`.\n- `supabase/migrations/`: Contains SQL scripts for setting up Supabase.\n- `.env`: Environment variables.\n- `Dockerfile`: Docker configuration.\n- `docker-compose.yml`: Compose file to run the application.\n- `install.sh`: Installation script.\n- `pyproject.toml`: Poetry configuration.\n- `README.md`: Project documentation.\n\n---\n\n## Installation Bash Script (`install.sh`)\n\n```bash\n#!/bin/bash\n\n# Check if Poetry is installed\nif ! command -v poetry &> /dev/null\nthen\n    echo \"Poetry not found. Installing Poetry...\"\n    curl -sSL https://install.python-poetry.org | python3 -\n    export PATH=\"$HOME/.local/bin:$PATH\"\nfi\n\n# Install project dependencies\necho \"Installing dependencies with Poetry...\"\npoetry install\n\necho \"Dependencies installed successfully.\"\n```\n\n**Make sure to give execution permissions to the script:**\n\n```bash\nchmod +x install.sh\n```\n\n---\n\n## Dockerfile\n\n```dockerfile\n# Use the official Python slim image\nFROM python:3.9-slim\n\n# Set environment variables\nENV PYTHONUNBUFFERED=1\nENV PYTHONDONTWRITEBYTECODE=1\n\n# Set the working directory\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y \\\n    curl \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Poetry\nRUN curl -sSL https://install.python-poetry.org | python3 -\nENV PATH=\"/root/.local/bin:$PATH\"\n\n# Copy project files\nCOPY pyproject.toml poetry.lock /app/\nCOPY app /app/app\nCOPY install.sh /app/\nCOPY .env /app/\n\n# Install project dependencies\nRUN poetry config virtualenvs.create false \\\n    && poetry install --no-dev --no-interaction --no-ansi\n\n# Expose the port\nEXPOSE 8000\n\n# Command to run the application\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n---\n\n## Poetry Configuration (`pyproject.toml`)\n\n```toml\n[tool.poetry]\nname = \"contextual_retrieval\"\nversion = \"0.1.0\"\ndescription = \"Contextual Retrieval using OpenAI GPT-4, LlamaIndex, LiteLLM, and Supabase\"\nauthors = [\"Your Name <your.email@example.com>\"]\nlicense = \"MIT\"\nreadme = \"README.md\"\n\n[tool.poetry.dependencies]\npython = \"^3.9\"\nfastapi = \"^0.95.2\"\nuvicorn = \"^0.21.1\"\nllama-index = \"^0.7.3\"\nlitellm = \"^0.1.1\"\nsupabase = \"^1.0.3\"\ndiskcache = \"^5.4.0\"\naiohttp = \"^3.8.1\"\nloguru = \"^0.6.0\"\npython-dotenv = \"^1.0.0\"\n\n[tool.poetry.dev-dependencies]\npytest = \"^7.1.2\"\n\n[build-system]\nrequires = [\"poetry-core\"]\nbuild-backend = \"poetry.core.masonry.api\"\n```\n\n---\n\n## FastAPI Asynchronous Application\n\n### `app/config.py`\n\n```python\nimport os\nfrom pydantic import BaseSettings\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\nclass Settings(BaseSettings):\n    openai_api_key: str = os.getenv(\"OPENAI_API_KEY\", \"\")\n    supabase_url: str = os.getenv(\"SUPABASE_URL\", \"\")\n    supabase_key: str = os.getenv(\"SUPABASE_KEY\", \"\")\n    supabase_bucket_name: str = os.getenv(\"SUPABASE_BUCKET_NAME\", \"documents\")\n\nsettings = Settings()\n```\n\n### `app/supabase_client.py`\n\n```python\nfrom supabase import create_client, Client\nfrom app.config import settings\n\nsupabase: Client = create_client(settings.supabase_url, settings.supabase_key)\n```\n\n### `app/utils.py`\n\n```python\nimport asyncio\nfrom llama_index import Document\nfrom llama_index.text_splitter import TokenTextSplitter\nfrom litellm import completion, embedding\nfrom diskcache import Cache\nfrom loguru import logger\nfrom app.config import settings\nfrom app.supabase_client import supabase\n\ncache = Cache(\"./cache\")\n\nasync def generate_context(document: str, chunk: str) -> str:\n    prompt = f\"Document: {document}\\nChunk: {chunk}\\nProvide a succinct context for this chunk within the overall document.\"\n    cache_key = f\"context:{hash(prompt)}\"\n\n    if cache_key in cache:\n        logger.debug(\"Cache hit for context generation.\")\n        return cache[cache_key]\n    else:\n        logger.debug(\"Generating context using GPT-4.\")\n        response = await completion(model=\"gpt-4\", messages=[{\"role\": \"user\", \"content\": prompt}])\n        context = response.choices[0].message.content\n        cache[cache_key] = context\n        return context\n\nasync def contextualize_document(doc: Document) -> list:\n    text_splitter = TokenTextSplitter(chunk_size=500, chunk_overlap=50)\n    chunks = text_splitter.split_text(doc.text)\n    contextualized_chunks = []\n\n    tasks = [generate_context(doc.text, chunk) for chunk in chunks]\n    contexts = await asyncio.gather(*tasks)\n\n    for context, chunk in zip(contexts, chunks):\n        contextualized_text = f\"{context} {chunk}\"\n        contextualized_chunks.append(Document(text=contextualized_text))\n    return contextualized_chunks\n\nasync def store_embedding(text: str, embedding_vector: list):\n    data = supabase.table('embeddings').insert({\n        'content': text,\n        'embedding': embedding_vector\n    }).execute()\n    return data\n\nasync def search_embeddings(query_embedding: list, match_threshold: float, match_count: int):\n    response = supabase.rpc('match_documents', {\n        'query_embedding': query_embedding,\n        'match_threshold': match_threshold,\n        'match_count': match_count\n    }).execute()\n    return response.data\n```\n\n### `app/main.py`\n\n```python\nfrom fastapi import FastAPI, UploadFile, File\nimport asyncio\nfrom llama_index import Document\nfrom app.utils import contextualize_document, store_embedding, search_embeddings\nfrom app.config import settings\nfrom app.supabase_client import supabase\nfrom litellm import embedding\nfrom loguru import logger\nfrom io import BytesIO\n\napp = FastAPI()\n\n@app.on_event(\"startup\")\nasync def startup_event():\n    logger.info(\"Fetching documents from Supabase Storage...\")\n    bucket = supabase.storage.from_(settings.supabase_bucket_name)\n    documents_list = bucket.list().get('data', [])\n\n    documents = []\n\n    for doc in documents_list:\n        file_name = doc['name']\n        # Download the file content\n        response = bucket.download(file_name)\n        file_content = response.decode('utf-8')  # Adjust decoding if necessary\n        documents.append(Document(text=file_content))\n\n    logger.info(f\"Loaded {len(documents)} documents.\")\n\n    logger.info(\"Contextualizing documents...\")\n    tasks = [contextualize_document(doc) for doc in documents]\n    results = await asyncio.gather(*tasks)\n    contextualized_documents = [doc for sublist in results for doc in sublist]\n    logger.info(f\"Contextualized into {len(contextualized_documents)} chunks.\")\n\n    logger.info(\"Storing embeddings...\")\n    for doc in contextualized_documents:\n        embed_response = await embedding(model=\"text-embedding-ada-002\", input=doc.text)\n        await store_embedding(doc.text, embed_response.data[0].embedding)\n    logger.info(\"Embeddings stored successfully.\")\n\n@app.get(\"/search\")\nasync def search(query: str, threshold: float = 0.7, count: int = 10):\n    embed_response = await embedding(model=\"text-embedding-ada-002\", input=query)\n    query_embedding = embed_response.data[0].embedding\n    results = await search_embeddings(query_embedding, threshold, count)\n    return {\"results\": results}\n\n@app.post(\"/upload\")\nasync def upload_document(file: UploadFile = File(...)):\n    # Upload to Supabase Storage\n    bucket = supabase.storage.from_(settings.supabase_bucket_name)\n    content = await file.read()\n    bucket.upload(file.filename, content)\n\n    return {\"message\": \"File uploaded successfully\"}\n```\n\n### `app/__init__.py`\n\n```python\n# This file is intentionally left blank to make 'app' a package.\n```\n\n---\n\n## SQL for Supabase (`supabase/migrations/20231018000000_create_embeddings_table.sql`)\n\n```sql\n-- Enable the pgvector extension to work with embedding vectors\nCREATE EXTENSION IF NOT EXISTS vector;\n\n-- Create a table to store document embeddings\nCREATE TABLE embeddings (\n  id BIGSERIAL PRIMARY KEY,\n  content TEXT,\n  embedding VECTOR(1536)\n);\n\n-- Create a function to match documents based on embedding similarity\nCREATE OR REPLACE FUNCTION match_documents (\n  query_embedding VECTOR(1536),\n  match_threshold FLOAT,\n  match_count INT\n)\nRETURNS TABLE (\n  id BIGINT,\n  content TEXT,\n  similarity FLOAT\n)\nLANGUAGE plpgsql\nAS $$\nBEGIN\n  RETURN QUERY\n  SELECT\n    id,\n    content,\n    1 - (embeddings.embedding <=> query_embedding) AS similarity\n  FROM embeddings\n  WHERE 1 - (embeddings.embedding <=> query_embedding) > match_threshold\n  ORDER BY embeddings.embedding <=> query_embedding\n  LIMIT match_count;\nEND;\n$$;\n\n-- Create an index on the embedding column to speed up similarity searches\nCREATE INDEX ON embeddings USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);\n```\n\n---\n\n## Environment Variables (`.env`)\n\nCreate a `.env` file in the root directory with the following content:\n\n```dotenv\nOPENAI_API_KEY=your_openai_api_key_here\nSUPABASE_URL=your_supabase_url_here\nSUPABASE_KEY=your_supabase_service_role_key_here\nSUPABASE_BUCKET_NAME=documents\n```\n\n**Notes:**\n\n- Replace the placeholder values with your actual API keys and URLs.\n- Use the **service role key** for `SUPABASE_KEY` to allow server-side operations like uploading and downloading files.\n- Do not share this information publicly.\n- Add `.env` to your `.gitignore` file to prevent it from being committed to version control.\n\n---\n\n## Docker Compose (`docker-compose.yml`)\n\n```yaml\nversion: '3.8'\n\nservices:\n  app:\n    build: .\n    ports:\n      - \"8000:8000\"\n    environment:\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n      - SUPABASE_URL=${SUPABASE_URL}\n      - SUPABASE_KEY=${SUPABASE_KEY}\n      - SUPABASE_BUCKET_NAME=${SUPABASE_BUCKET_NAME}\n    volumes:\n      - ./app:/app/app\n      - ./cache:/app/cache\n    env_file:\n      - .env\n```\n\n---\n\n## Running the Application\n\n### Prerequisites\n\n- **Python 3.9** installed on your machine.\n- **Poetry** installed.\n- **Docker** and **Docker Compose** installed (if running with Docker).\n- An **OpenAI API key**.\n- A **Supabase** project with `pgvector` extension enabled and a storage bucket set up.\n\n### Steps\n\n1. **Clone the Repository**\n\n   ```bash\n   git clone https://github.com/yourusername/contextual_retrieval.git\n   cd contextual_retrieval\n   ```\n\n2. **Set Up Supabase**\n\n   - **Create a Supabase Project**:\n     - Go to [Supabase](https://supabase.com/) and create a new project.\n   - **Enable `pgvector` Extension**:\n     - In the SQL editor of your Supabase dashboard, run:\n\n       ```sql\n       CREATE EXTENSION IF NOT EXISTS vector;\n       ```\n\n   - **Run Migration Script**:\n     - Copy the content of `supabase/migrations/20231018000000_create_embeddings_table.sql` and execute it in the SQL editor to set up the necessary database schema.\n   - **Create a Storage Bucket**:\n     - In the Supabase dashboard, navigate to **Storage** and create a new bucket named `documents`.\n\n3. **Set Up Environment Variables**\n\n   - Update the `.env` file with your OpenAI API key and Supabase configurations.\n\n4. **Install Dependencies**\n\n   - Make the installation script executable:\n\n     ```bash\n     chmod +x install.sh\n     ```\n\n   - Run the installation script:\n\n     ```bash\n     ./install.sh\n     ```\n\n     This will install all the required dependencies using Poetry.\n\n5. **Run the Application**\n\n   - Start the FastAPI application:\n\n     ```bash\n     uvicorn app.main:app --host 0.0.0.0 --port 8000\n     ```\n\n     The application will download documents from Supabase Storage and process them during startup.\n\n6. **Access the API**\n\n   - The API is now accessible at `http://localhost:8000`.\n   - **Search Endpoint**:\n\n     ```http\n     GET http://localhost:8000/search?query=Your+search+query\n     ```\n\n   - **Upload Endpoint**:\n\n     You can upload new documents via the `/upload` endpoint using a tool like `curl` or Postman.\n\n     Example using `curl`:\n\n     ```bash\n     curl -X POST \"http://localhost:8000/upload\" -F \"file=@/path/to/your/document.txt\"\n     ```\n\n7. **Monitor Logs**\n\n   - Keep an eye on the terminal output for any logging information or errors.\n\n---\n\n## API Endpoints\n\n- **`GET /search`**: Search for documents.\n\n  - **Query Parameters**:\n    - `query` (string): The search query.\n    - `threshold` (float, default `0.7`): Similarity threshold.\n    - `count` (int, default `10`): Number of results to return.\n\n- **`POST /upload`**: Upload a new document to the system.\n\n  - **Form Data**:\n    - `file`: The file to upload.\n\n---\n\n## Additional Recommendations Implemented\n\n- **Supabase Storage Integration**\n\n  - Modified the application to use Supabase Storage for storing and retrieving documents.\n  - Documents are fetched from Supabase Storage during application startup.\n\n- **Error Handling and Logging**\n\n  - Used the `loguru` library to add logging statements throughout the application.\n  - Implemented error handling for various cases, such as network errors during file uploads/downloads.\n\n- **Caching**\n\n  - Implemented caching using `diskcache` to store and reuse generated contexts and embeddings, reducing API calls and costs.\n\n- **Parallel Processing**\n\n  - Used `asyncio.gather` to concurrently generate contexts and embeddings for document chunks, improving performance.\n\n- **Environment Variable Management**\n\n  - Used `python-dotenv` to securely manage environment variables.\n\n- **Rate Limiting and API Usage**\n\n  - The caching mechanism helps in reducing the number of API calls to OpenAI, mitigating rate limit issues.\n\n- **Logging and Monitoring**\n\n  - Detailed logging helps in monitoring the application's performance and debugging issues.\n\n---\n\n## Notes and Best Practices\n\n- **Security**\n\n  - Use the Supabase **service role key** for server-side operations and keep it secure.\n  - Do not expose sensitive keys in client-side code or public repositories.\n  - Ensure that your Supabase Storage bucket has appropriate access policies.\n\n- **Data Handling**\n\n  - Be cautious if your documents contain sensitive information; ensure that all data transfers are secure.\n  - Implement SSL/TLS for secure communication between your application and Supabase.\n\n- **Error Handling**\n\n  - Add robust error handling for network issues, API errors, and unexpected exceptions.\n  - Validate inputs received from users to prevent injection attacks.\n\n- **Scaling**\n\n  - Monitor performance and consider scaling strategies as your dataset grows.\n  - Use asynchronous processing and efficient data structures to handle large volumes of data.\n\n---\n\n## Conclusion\n\nThis updated implementation of the Contextual Retrieval System integrates Supabase Storage for document storage, providing a centralized and scalable solution for managing documents. By leveraging Supabase for both vector storage and document storage, the system offers improved scalability, manageability, and efficiency.\n\nThe application incorporates best practices such as caching, asynchronous processing, and secure environment variable management to ensure efficient and secure operation. By integrating context into the retrieval process, the system offers improved accuracy, enhanced relevance, and a better user experience.\n\n---\n\n**Disclaimer:** Be mindful of the costs associated with using OpenAI's API and Supabase services. Monitor your usage and set appropriate limits to prevent unexpected charges. Always handle API keys and sensitive data securely.",
      "encoding": "utf-8"
    }
  },
  "public": true,
  "created_at": "2024-10-01T01:09:10Z",
  "updated_at": "2026-01-19T05:49:54Z",
  "description": "Contextual Retrieval system",
  "comments": 0,
  "user": null,
  "comments_enabled": true,
  "comments_url": "https://api.github.com/gists/6959450aa7fe0e919ff52b05e3c26a44/comments",
  "owner": {
    "login": "ruvnet",
    "id": 2934394,
    "node_id": "MDQ6VXNlcjI5MzQzOTQ=",
    "avatar_url": "https://avatars.githubusercontent.com/u/2934394?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ruvnet",
    "html_url": "https://github.com/ruvnet",
    "followers_url": "https://api.github.com/users/ruvnet/followers",
    "following_url": "https://api.github.com/users/ruvnet/following{/other_user}",
    "gists_url": "https://api.github.com/users/ruvnet/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ruvnet/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ruvnet/subscriptions",
    "organizations_url": "https://api.github.com/users/ruvnet/orgs",
    "repos_url": "https://api.github.com/users/ruvnet/repos",
    "events_url": "https://api.github.com/users/ruvnet/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ruvnet/received_events",
    "type": "User",
    "user_view_type": "public",
    "site_admin": false
  },
  "forks": [
    {
      "url": "https://api.github.com/gists/9706acd34c126d2ad71f115f1c64f032",
      "user": {
        "login": "n4s5ti",
        "id": 77896784,
        "node_id": "MDQ6VXNlcjc3ODk2Nzg0",
        "avatar_url": "https://avatars.githubusercontent.com/u/77896784?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/n4s5ti",
        "html_url": "https://github.com/n4s5ti",
        "followers_url": "https://api.github.com/users/n4s5ti/followers",
        "following_url": "https://api.github.com/users/n4s5ti/following{/other_user}",
        "gists_url": "https://api.github.com/users/n4s5ti/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/n4s5ti/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/n4s5ti/subscriptions",
        "organizations_url": "https://api.github.com/users/n4s5ti/orgs",
        "repos_url": "https://api.github.com/users/n4s5ti/repos",
        "events_url": "https://api.github.com/users/n4s5ti/events{/privacy}",
        "received_events_url": "https://api.github.com/users/n4s5ti/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false,
        "name": null,
        "company": null,
        "blog": "",
        "location": null,
        "email": null,
        "hireable": null,
        "bio": null,
        "twitter_username": null,
        "public_repos": 105,
        "public_gists": 103,
        "followers": 9,
        "following": 60,
        "created_at": "2021-01-23T18:37:16Z",
        "updated_at": "2026-01-20T22:26:03Z"
      },
      "id": "9706acd34c126d2ad71f115f1c64f032",
      "created_at": "2025-11-07T13:38:55Z",
      "updated_at": "2025-11-07T13:38:55Z"
    },
    {
      "url": "https://api.github.com/gists/14b25d4c38a5a69ad238c0d9c4395603",
      "user": {
        "login": "imakealol",
        "id": 39782739,
        "node_id": "MDQ6VXNlcjM5NzgyNzM5",
        "avatar_url": "https://avatars.githubusercontent.com/u/39782739?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/imakealol",
        "html_url": "https://github.com/imakealol",
        "followers_url": "https://api.github.com/users/imakealol/followers",
        "following_url": "https://api.github.com/users/imakealol/following{/other_user}",
        "gists_url": "https://api.github.com/users/imakealol/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/imakealol/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/imakealol/subscriptions",
        "organizations_url": "https://api.github.com/users/imakealol/orgs",
        "repos_url": "https://api.github.com/users/imakealol/repos",
        "events_url": "https://api.github.com/users/imakealol/events{/privacy}",
        "received_events_url": "https://api.github.com/users/imakealol/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false,
        "name": null,
        "company": null,
        "blog": "",
        "location": null,
        "email": "webmaster@terror-irc.de",
        "hireable": null,
        "bio": null,
        "twitter_username": null,
        "public_repos": 183,
        "public_gists": 48,
        "followers": 1,
        "following": 7,
        "created_at": "2018-05-31T00:25:12Z",
        "updated_at": "2026-01-10T18:53:08Z"
      },
      "id": "14b25d4c38a5a69ad238c0d9c4395603",
      "created_at": "2026-01-19T05:49:53Z",
      "updated_at": "2026-01-19T05:49:54Z"
    }
  ],
  "history": [
    {
      "user": {
        "login": "ruvnet",
        "id": 2934394,
        "node_id": "MDQ6VXNlcjI5MzQzOTQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2934394?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ruvnet",
        "html_url": "https://github.com/ruvnet",
        "followers_url": "https://api.github.com/users/ruvnet/followers",
        "following_url": "https://api.github.com/users/ruvnet/following{/other_user}",
        "gists_url": "https://api.github.com/users/ruvnet/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/ruvnet/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/ruvnet/subscriptions",
        "organizations_url": "https://api.github.com/users/ruvnet/orgs",
        "repos_url": "https://api.github.com/users/ruvnet/repos",
        "events_url": "https://api.github.com/users/ruvnet/events{/privacy}",
        "received_events_url": "https://api.github.com/users/ruvnet/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
      },
      "version": "96c9f7758bc8003276547a0f588aa25a434d9c1f",
      "committed_at": "2024-10-18T14:31:06Z",
      "change_status": {
        "total": 279,
        "additions": 105,
        "deletions": 174
      },
      "url": "https://api.github.com/gists/6959450aa7fe0e919ff52b05e3c26a44/96c9f7758bc8003276547a0f588aa25a434d9c1f"
    },
    {
      "user": {
        "login": "ruvnet",
        "id": 2934394,
        "node_id": "MDQ6VXNlcjI5MzQzOTQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2934394?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ruvnet",
        "html_url": "https://github.com/ruvnet",
        "followers_url": "https://api.github.com/users/ruvnet/followers",
        "following_url": "https://api.github.com/users/ruvnet/following{/other_user}",
        "gists_url": "https://api.github.com/users/ruvnet/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/ruvnet/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/ruvnet/subscriptions",
        "organizations_url": "https://api.github.com/users/ruvnet/orgs",
        "repos_url": "https://api.github.com/users/ruvnet/repos",
        "events_url": "https://api.github.com/users/ruvnet/events{/privacy}",
        "received_events_url": "https://api.github.com/users/ruvnet/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
      },
      "version": "c717f71d6287fa2ff07f84eeefc2a96d766448bb",
      "committed_at": "2024-10-18T14:26:15Z",
      "change_status": {
        "total": 137,
        "additions": 137,
        "deletions": 0
      },
      "url": "https://api.github.com/gists/6959450aa7fe0e919ff52b05e3c26a44/c717f71d6287fa2ff07f84eeefc2a96d766448bb"
    },
    {
      "user": {
        "login": "ruvnet",
        "id": 2934394,
        "node_id": "MDQ6VXNlcjI5MzQzOTQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2934394?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ruvnet",
        "html_url": "https://github.com/ruvnet",
        "followers_url": "https://api.github.com/users/ruvnet/followers",
        "following_url": "https://api.github.com/users/ruvnet/following{/other_user}",
        "gists_url": "https://api.github.com/users/ruvnet/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/ruvnet/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/ruvnet/subscriptions",
        "organizations_url": "https://api.github.com/users/ruvnet/orgs",
        "repos_url": "https://api.github.com/users/ruvnet/repos",
        "events_url": "https://api.github.com/users/ruvnet/events{/privacy}",
        "received_events_url": "https://api.github.com/users/ruvnet/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
      },
      "version": "9aa226c506bb855ae55c185e801e288ec4e2752d",
      "committed_at": "2024-10-18T14:24:02Z",
      "change_status": {
        "total": 341,
        "additions": 204,
        "deletions": 137
      },
      "url": "https://api.github.com/gists/6959450aa7fe0e919ff52b05e3c26a44/9aa226c506bb855ae55c185e801e288ec4e2752d"
    },
    {
      "user": {
        "login": "ruvnet",
        "id": 2934394,
        "node_id": "MDQ6VXNlcjI5MzQzOTQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2934394?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ruvnet",
        "html_url": "https://github.com/ruvnet",
        "followers_url": "https://api.github.com/users/ruvnet/followers",
        "following_url": "https://api.github.com/users/ruvnet/following{/other_user}",
        "gists_url": "https://api.github.com/users/ruvnet/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/ruvnet/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/ruvnet/subscriptions",
        "organizations_url": "https://api.github.com/users/ruvnet/orgs",
        "repos_url": "https://api.github.com/users/ruvnet/repos",
        "events_url": "https://api.github.com/users/ruvnet/events{/privacy}",
        "received_events_url": "https://api.github.com/users/ruvnet/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
      },
      "version": "2ed1708611d28ecf54c05db137943873754d0810",
      "committed_at": "2024-10-01T01:12:52Z",
      "change_status": {
        "total": 4,
        "additions": 3,
        "deletions": 1
      },
      "url": "https://api.github.com/gists/6959450aa7fe0e919ff52b05e3c26a44/2ed1708611d28ecf54c05db137943873754d0810"
    },
    {
      "user": {
        "login": "ruvnet",
        "id": 2934394,
        "node_id": "MDQ6VXNlcjI5MzQzOTQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2934394?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ruvnet",
        "html_url": "https://github.com/ruvnet",
        "followers_url": "https://api.github.com/users/ruvnet/followers",
        "following_url": "https://api.github.com/users/ruvnet/following{/other_user}",
        "gists_url": "https://api.github.com/users/ruvnet/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/ruvnet/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/ruvnet/subscriptions",
        "organizations_url": "https://api.github.com/users/ruvnet/orgs",
        "repos_url": "https://api.github.com/users/ruvnet/repos",
        "events_url": "https://api.github.com/users/ruvnet/events{/privacy}",
        "received_events_url": "https://api.github.com/users/ruvnet/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
      },
      "version": "1377be5339b3c47d33081e082a55237443d399ea",
      "committed_at": "2024-10-01T01:11:58Z",
      "change_status": {
        "total": 18,
        "additions": 18,
        "deletions": 0
      },
      "url": "https://api.github.com/gists/6959450aa7fe0e919ff52b05e3c26a44/1377be5339b3c47d33081e082a55237443d399ea"
    },
    {
      "user": {
        "login": "ruvnet",
        "id": 2934394,
        "node_id": "MDQ6VXNlcjI5MzQzOTQ=",
        "avatar_url": "https://avatars.githubusercontent.com/u/2934394?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/ruvnet",
        "html_url": "https://github.com/ruvnet",
        "followers_url": "https://api.github.com/users/ruvnet/followers",
        "following_url": "https://api.github.com/users/ruvnet/following{/other_user}",
        "gists_url": "https://api.github.com/users/ruvnet/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/ruvnet/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/ruvnet/subscriptions",
        "organizations_url": "https://api.github.com/users/ruvnet/orgs",
        "repos_url": "https://api.github.com/users/ruvnet/repos",
        "events_url": "https://api.github.com/users/ruvnet/events{/privacy}",
        "received_events_url": "https://api.github.com/users/ruvnet/received_events",
        "type": "User",
        "user_view_type": "public",
        "site_admin": false
      },
      "version": "7f6001fba002a189a8043d8dc533a1e4bee27c61",
      "committed_at": "2024-10-01T01:09:10Z",
      "change_status": {
        "total": 432,
        "additions": 432,
        "deletions": 0
      },
      "url": "https://api.github.com/gists/6959450aa7fe0e919ff52b05e3c26a44/7f6001fba002a189a8043d8dc533a1e4bee27c61"
    }
  ],
  "truncated": false,
  "type": "gist",
  "commit": "96c9f7758bc8003276547a0f588aa25a434d9c1f",
  "lastUpdated": "2026-01-30T15:12:47+00:00"
}
