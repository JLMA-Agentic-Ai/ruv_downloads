{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OpenAI JSON Mode vs. Function Calling\n",
        "This tutorial explores the differences between JSON mode and function calling in the OpenAI API, providing insights into when and how to use each method effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "Before we dive into the examples, ensure that you have the OpenAI library installed. Use the following command to install it if you haven't done so already."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuring LLM Settings with UI Elements\n",
        "To make our tutorial more interactive, we'll use IPython widgets to allow you to adjust the settings of the Large Language Model (LLM) such as the model version and temperature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Widget for model selection\n",
        "model_selector = widgets.Dropdown(\n",
        "    options=['gpt-3.5-turbo', 'gpt-3.5-turbo-0125', 'text-davinci-003'],\n",
        "    value='gpt-3.5-turbo-0125',\n",
        "    description='Model:',\n",
        ")\n",
        "\n",
        "# Widget for temperature setting\n",
        "temperature_slider = widgets.FloatSlider(\n",
        "    value=0.5,\n",
        "    min=0,\n",
        "    max=1.0,\n",
        "    step=0.01,\n",
        "    description='Temperature:',\n",
        ")\n",
        "\n",
        "display(model_selector, temperature_slider)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "The OpenAI API offers two primary methods for obtaining structured output responses from GPT models: JSON mode and function calling. Understanding the nuances of each can significantly enhance your workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## JSON Mode\n",
        "In JSON mode, outputs are formatted as valid JSON strings. It's essential to specify the desired JSON structure within the prompt. Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "system_prompt = \"\"\"You are a helpful assistant designed to output this JSON format:\n",
        "```\n",
        "{\n",
        "    \\\"answer\\\": \\\"<your response to the user's question>\\\"\n",
        "}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "response = openai.chat.completions.create(\n",
        "  model=model_selector.value,\n",
        "  temperature=temperature_slider.value,\n",
        "  response_format={\"type\": \"json_object\"},\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
            "## Function Calling\n",
            "Function calling allows GPT models to call predefined functions instead of generating text. If a `tool_choice` is provided, the model will use that specific function. Here's how it's implemented:"
        ]
    },
    {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
            "import openai\n",
            "\n",
            "functions = [\n",
            "    {\n",
            "        \"type\": \"function\",\n",
            "        \"function\": {\n",
            "            \"name\": \"get_world_series_winner\",\n",
            "            \"description\": \"Get the world series winner in a given year\",\n",
            "            \"parameters\": {\n",
            "                \"type\": \"object\",\n",
            "                \"properties\": {\n",
            "                    \"year\": {\"type\": \"integer\"}\n",
            "                },\n",
            "                \"required\": [\"year\"],\n",
            "            },\n",
            "        },\n",
            "    }\n",
            "]\n",
            "\n",
            "response = openai.chat.completions.create(\n",
            "  model=model_selector.value,\n",
            "  temperature=temperature_slider.value,\n",
            "  tools=functions,\n",
            "  tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_world_series_winner\"}},\n",
            "  messages=[\n",
            "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}\n",
            "  ]\n",
            ")\n",
            "\n",
            "print(response.choices[0].message.tool_calls)"
        ]
    },
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "## Combining JSON Mode and Function Calling\n",
            "JSON mode and function calling can be used together for more complex needs. This allows for a flexible approach that leverages the best of both worlds."
        ]
    },
    {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
            "import openai\n",
            "\n",
            "system_prompt = \"\"\"You are a helpful assistant designed to output this JSON format:\n",
            "```\n",
            "{\n",
            "    \\\"functions\\\": [\n",
            "        {\n",
            "            \\\"name\\\": \\\"<Function name>\\\",\n",
            "            \\\"arguments\\\": {\n",
            "                \\\"<argument name>\\\": <argument value>\n",
            "            }\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "```\n",
            "\"\"\"\n",
            "\n",
            "response = openai.chat.completions.create(\n",
            "  model=model_selector.value,\n",
            "  temperature=temperature_slider.value,\n",
            "  response_format={\"type\": \"json_object\"},\n",
            "  tool_choice=\"none\",  # to force the response to be in free-form text\n",
            "  tools=functions,\n",
            "  messages=[\n",
            "    {\"role\": \"system\", \"content\": system_prompt},\n",
            "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}\n",
            "  ]\n",
            ")\n",
            "\n",
            "print(response.choices[0].message.content)"
        ]
    },
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "## When to Use Each\n",
            "Function calling is specifically designed for scenarios with a structured JSON format to call predefined functions. JSON mode, on the other hand, is more flexible but requires the model to always output valid JSON strings. Depending on your application's needs, choosing the appropriate method can enhance efficiency and accuracy."
        ]
    },
    {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "## Conclusion\n",
            "Understanding the differences between JSON mode and function calling within the OpenAI API framework is crucial for optimizing your interaction with GPT models. Both methods offer unique advantages, and their effective application can lead to more precise and useful AI-generated responses."
        ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}